[
  {
    "model_name": "openchat",
    "model_id": "openchat-3.5-0106",
    "backend": "openai_compatible",
    "release_date": "06-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "codellama-34b",
    "model_id": "codellama-34b-instruct",
    "backend": "openai_compatible",
    "release_date": "24-08-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "Llama-3-70B-Instruct-Anyscale",
    "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Llama-3-70B-Together.ai",
    "model_id": "meta-llama/Llama-3-70b-chat-hf",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Llama-3-8B-Together.ai",
    "model_id": "meta-llama/Llama-3-8b-chat-hf",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "Llama-3-8B-Instruct-Anyscale",
    "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "Meta-Llama-3.1-405B-Instruct-Turbo",
    "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "backend": "openai_compatible",
    "release_date": "23-07-24",
    "open_weight": true,
    "parameters": "405B"
  },
  {
    "model_name": "Mixtral-8x22B-Instruct-v0.1",
    "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "backend": "openai_compatible",
    "release_date": "17-04-24",
    "open_weight": true,
    "parameters": "141B"
  },
  {
    "model_name": "Mixtral-8x7B-Instruct-v0.1",
    "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "backend": "openai_compatible",
    "release_date": "11-12-23",
    "open_weight": true,
    "parameters": "46.7B"
  },
  {
    "model_name": "fsc-openchat-3.5-0106",
    "model_id": "openchat-3.5-0106",
    "backend": "openai_compatible",
    "release_date": "06-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "fsc-codellama-34b-instruct",
    "model_id": "codellama-34b-instruct",
    "backend": "openai_compatible",
    "release_date": "24-08-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "gpt-4-1106-vision-preview",
    "model_id": "gpt-4-1106-vision-preview",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "06-11-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "1.76T"
  },
  {
    "model_name": "gpt-4o-2024-05-13",
    "model_id": "gpt-4o-2024-05-13",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "13-05-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "200B"
  },
  {
    "model_name": "gpt-4o-2024-08-06",
    "model_id": "gpt-4o-2024-08-06",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "06-08-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "200B"
  },
  {
    "model_name": "gpt-4o-mini-2024-07-18",
    "model_id": "gpt-4o-mini-2024-07-18",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "18-07-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "8B"
  },
  {
    "model_name": "gpt-4-turbo-2024-04-09",
    "model_id": "gpt-4-turbo-2024-04-09",
    "backend": "openai",
    "release_date": "09-04-24",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-4-1106-preview",
    "model_id": "gpt-4-1106-preview",
    "backend": "openai",
    "release_date": "06-11-23",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-4-0125-preview",
    "model_id": "gpt-4-0125-preview",
    "backend": "openai",
    "release_date": "25-01-24",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-3.5-turbo-0125",
    "model_id": "gpt-3.5-turbo-0125",
    "backend": "openai",
    "release_date": "25-01-24",
    "open_weight": false,
    "parameters": "175B"
  },
  {
    "model_name": "gpt-4-0613",
    "model_id": "gpt-4-0613",
    "backend": "openai",
    "release_date": "13-06-23",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-4-0314",
    "model_id": "gpt-4-0314",
    "backend": "openai",
    "release_date": "14-03-23",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-3.5-turbo-1106",
    "model_id": "gpt-3.5-turbo-1106",
    "backend": "openai",
    "release_date": "06-11-23",
    "open_weight": false,
    "parameters": "175B"
  },
  {
    "model_name": "gpt-3.5-turbo-0613",
    "model_id": "gpt-3.5-turbo-0613",
    "backend": "openai",
    "release_date": "13-06-23",
    "open_weight": false,
    "parameters": "175B"
  },
  {
    "model_name": "mistral-medium-2312",
    "model_id": "mistral-medium-2312",
    "backend": "mistral",
    "release_date": "01-12-23",
    "open_weight": true,
    "parameters": "",
    "estimated_parameters": "141B"
  },
  {
    "model_name": "mistral-tiny-2312",
    "model_id": "mistral-tiny-2312",
    "backend": "mistral",
    "release_date": "01-12-23",
    "open_weight": true,
    "parameters": "",
    "estimated_parameters": "7B"
  },
  {
    "model_name": "mistral-small-2312",
    "model_id": "mistral-small-2312",
    "backend": "mistral",
    "release_date": "01-12-23",
    "open_weight": true,
    "parameters": "",
    "estimated_parameters": "46.7B"
  },
  {
    "model_name": "mistral-large-2402",
    "model_id": "mistral-large-2402",
    "backend": "mistral",
    "release_date": "01-02-24",
    "open_weight": true,
    "parameters": "123B"
  },
  {
    "model_name": "command",
    "model_id": "command",
    "backend": "cohere",
    "release_date": "01-12-22",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "command-r",
    "model_id": "command-r",
    "backend": "cohere",
    "release_date": "01-03-24",
    "open_weight": true,
    "parameters": "35B"
  },
  {
    "model_name": "command-r-plus",
    "model_id": "command-r-plus",
    "backend": "cohere",
    "release_date": "01-04-24",
    "open_weight": true,
    "parameters": "104B"
  },
  {
    "model_name": "command-light",
    "model_id": "command-light",
    "backend": "cohere",
    "release_date": "01-12-22",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-v1.3",
    "model_id": "claude-v1.3",
    "backend": "anthropic",
    "release_date": "18-04-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-v1.3-100k",
    "model_id": "claude-v1.3-100k",
    "backend": "anthropic",
    "release_date": "18-03-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-instant-1.2",
    "model_id": "claude-instant-1.2",
    "backend": "anthropic",
    "release_date": "09-08-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-2",
    "model_id": "claude-2",
    "backend": "anthropic",
    "release_date": "11-07-23",
    "open_weight": false,
    "parameters": "137B"
  },
  {
    "model_name": "claude-2.1",
    "model_id": "claude-2.1",
    "backend": "anthropic",
    "release_date": "21-11-23",
    "open_weight": false,
    "parameters": "137B"
  },
  {
    "model_name": "claude-3-opus-20240229",
    "model_id": "claude-3-opus-20240229",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "29-02-24",
    "open_weight": false,
    "parameters": "2T"
  },
  {
    "model_name": "claude-3-sonnet-20240229",
    "model_id": "claude-3-sonnet-20240229",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "29-02-24",
    "open_weight": false,
    "parameters": "70B"
  },
  {
    "model_name": "claude-3-haiku-20240307",
    "model_id": "claude-3-haiku-20240307",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "07-03-24",
    "open_weight": false,
    "parameters": "20B"
  },
  {
    "model_name": "claude-3-5-sonnet-20240620",
    "model_id": "claude-3-5-sonnet-20240620",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "20-06-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.0-pro-001",
    "model_id": "gemini-1.0-pro-001",
    "backend": "google",
    "release_date": "15-02-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
 {
    "model_name": "gemini-1.0-pro-002",
    "model_id": "gemini-1.0-pro-002",
    "backend": "google",
    "release_date": "09-04-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.0-pro-vision-001",
    "model_id": "gemini-1.0-pro-vision-latest",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "15-02-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.5-flash-001",
    "model_id": "gemini-1.5-flash-001",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "24-05-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.5-pro-001",
    "model_id": "gemini-1.5-pro-001",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "24-05-24",
    "open_weight": false,
    "parameters": "1.5T"
  },
  {
    "model_name": "gemini-1.5-pro-exp-0801",
    "model_id": "gemini-1.5-pro-exp-0801",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "01-08-24",
    "open_weight": false,
    "parameters": "1.5T"
  },
  {
    "model_name": "luminous-supreme-control",
    "model_id": "luminous-supreme-control",
    "backend": "alephalpha",
    "release_date": "13-02-23",
    "open_weight": false,
    "parameters": "70B"
  },
  {
    "model_name": "luminous-supreme",
    "model_id": "luminous-supreme",
    "backend": "alephalpha",
    "release_date": "15-08-22",
    "open_weight": false,
    "parameters": "70B"
  },
  {
    "model_name": "luminous-extended",
    "model_id": "luminous-extended",
    "backend": "alephalpha",
    "release_date": "15-06-22",
    "open_weight": false,
    "parameters": "30B"
  },
  {
    "model_name": "luminous-base",
    "model_id": "luminous-base",
    "backend": "alephalpha",
    "release_date": "14-04-22",
    "open_weight": false,
    "parameters": "13B"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "mistralai/Mistral-7B-Instruct-v0.1",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "27-09-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "sheep-duck-llama-2-70b-v1.1",
    "backend": "huggingface_local",
    "huggingface_id": "Riiid/sheep-duck-llama-2-70b-v1.1",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "27-09-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "sheep-duck-llama-2-13b",
    "backend": "huggingface_local",
    "huggingface_id": "Riiid/sheep-duck-llama-2-13b",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "04-10-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "falcon-7b-instruct",
    "backend": "huggingface_local",
    "huggingface_id": "tiiuae/falcon-7b-instruct",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "<|endoftext|>",
    "release_date": "25-04-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "falcon-40b-instruct",
    "backend": "huggingface_local",
    "huggingface_id": "tiiuae/falcon-40b-instruct",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "<|endoftext|>",
    "release_date": "25-05-23",
    "open_weight": true,
    "parameters": "40B"
  },
  {
    "model_name": "oasst-sft-4-pythia-12b-epoch-3.5",
    "backend": "huggingface_local",
    "huggingface_id": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% elif message['role'] == 'assistant' %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>' }}{% endif %}{% if loop.last %}{{ '<|assistant|>' }}{% endif %}{% endfor %}",
    "eos_to_cull": "<|endoftext|>",
    "release_date": "03-04-23",
    "open_weight": true,
    "parameters": "12B"
  },
  {
    "model_name": "koala-13B-HF",
    "backend": "huggingface_local",
    "huggingface_id": "TheBloke/koala-13B-HF",
    "premade_chat_template": false,
    "custom_chat_template": "{{ 'BEGINNING OF CONVERSATION: ' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% elif message['role'] == 'assistant' %}{{ 'GPT: ' + message['content'] + ' ' }}{% endif %}{% if loop.last %}{{ 'GPT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "07-04-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "Wizard-Vicuna-13B-Uncensored-HF",
    "backend": "huggingface_local",
    "huggingface_id": "TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "13-05-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "WizardLM-70b-v1.0",
    "backend": "huggingface_local",
    "huggingface_id": "WizardLM/WizardLM-70b-v1.0",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "09-08-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "WizardLM-13b-v1.2",
    "backend": "huggingface_local",
    "huggingface_id": "WizardLM/WizardLM-13b-v1.2",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "25-07-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "vicuna-7b-v1.5",
    "backend": "huggingface_local",
    "huggingface_id": "lmsys/vicuna-7b-v1.5",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "29-07-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "vicuna-13b-v1.5",
    "backend": "huggingface_local",
    "huggingface_id": "lmsys/vicuna-13b-v1.5",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "29-07-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "vicuna-33b-v1.3",
    "backend": "huggingface_local",
    "huggingface_id": "lmsys/vicuna-33b-v1.3",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "21-06-23",
    "open_weight": true,
    "parameters": "33B"
  },
  {
    "model_name": "gpt4all-13b-snoozy",
    "backend": "huggingface_local",
    "huggingface_id": "nomic-ai/gpt4all-13b-snoozy",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "24-04-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "CodeLlama-34b-Instruct-hf",
    "backend": "huggingface_local",
    "huggingface_id": "codellama/CodeLlama-34b-Instruct-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "24-08-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "zephyr-7b-alpha",
    "backend": "huggingface_local",
    "huggingface_id": "HuggingFaceH4/zephyr-7b-alpha",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "09-10-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "zephyr-7b-beta",
    "backend": "huggingface_local",
    "huggingface_id": "HuggingFaceH4/zephyr-7b-beta",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "26-10-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "openchat_3.5",
    "backend": "huggingface_local",
    "huggingface_id": "openchat/openchat_3.5",
    "premade_chat_template": true,
    "eos_to_cull": "<|end_of_turn|>",
    "release_date": "30-10-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Yi-34B-Chat",
    "backend": "huggingface_local",
    "huggingface_id": "01-ai/Yi-34B-Chat",
    "premade_chat_template": true,
    "slow_tokenizer": true,
    "output_split_prefix": "assistant\n",
    "eos_to_cull": "<|im_end|>",
    "release_date": "22-11-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "deepseek-llm-7b-chat",
    "backend": "huggingface_local",
    "huggingface_id": "deepseek-ai/deepseek-llm-7b-chat",
    "premade_chat_template": true,
    "eos_to_cull": "<｜end▁of▁sentence｜>",
    "release_date": "29-11-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "deepseek-llm-67b-chat",
    "backend": "huggingface_local",
    "huggingface_id": "deepseek-ai/deepseek-llm-67b-chat",
    "premade_chat_template": true,
    "eos_to_cull": "<｜end▁of▁sentence｜>",
    "release_date": "29-11-23",
    "open_weight": true,
    "parameters": "67B"
  },
  {
    "model_name": "tulu-2-dpo-7b",
    "backend": "huggingface_local",
    "huggingface_id": "allenai/tulu-2-dpo-7b",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "13-11-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "tulu-2-dpo-70b",
    "backend": "huggingface_local",
    "huggingface_id": "allenai/tulu-2-dpo-70b",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "12-11-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Mixtral-8x7B-Instruct-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "11-12-23",
    "open_weight": true,
    "parameters": "46.7B"
  },
  {
    "model_name": "SUS-Chat-34B",
    "backend": "huggingface_local",
    "huggingface_id": "SUSTech/SUS-Chat-34B",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant: ' + message['content'] }}{% endif %}{% if loop.last %}{{ '### Assistant: ' }}{% endif %}{% endfor %}",
    "slow_tokenizer": true,
    "eos_to_cull": "<|endoftext|>",
    "release_date": "29-11-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "CodeLlama-70b-Instruct-hf",
    "backend": "huggingface_local",
    "huggingface_id": "codellama/CodeLlama-70b-Instruct-hf",
    "premade_chat_template": true,
    "eos_to_cull": "<step>",
    "release_date": "29-01-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "openchat-3.5-0106",
    "backend": "huggingface_local",
    "huggingface_id": "openchat/openchat-3.5-0106",
    "premade_chat_template": true,
    "eos_to_cull": "<|end_of_turn|>",
    "release_date": "06-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "openchat-3.5-1210",
    "backend": "huggingface_local",
    "huggingface_id": "openchat/openchat-3.5-1210",
    "premade_chat_template": true,
    "eos_to_cull": "<|end_of_turn|>",
    "release_date": "10-12-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Nous-Hermes-2-Mixtral-8x7B-DPO",
    "backend": "huggingface_local",
    "huggingface_id": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "premade_chat_template": true,
    "eos_to_cull": "<|im_end|>",
    "release_date": "11-01-24",
    "open_weight": true,
    "parameters": "46.7B"
  },
  {
    "model_name": "Smaug-72B-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "abacusai/Smaug-72B-v0.1",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
    "eos_to_cull": "<|endoftext|>",
    "release_date": "02-02-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Smaug-34B-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "abacusai/Smaug-34B-v0.1",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
    "eos_to_cull": "<|endoftext|>",
    "release_date": "25-01-24",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "Qwen1.5-7B-Chat",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen1.5-7B-Chat",
    "premade_chat_template": true,
    "eos_to_cull": "<|im_end|>",
    "release_date": "30-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Qwen1.5-72B-Chat",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen1.5-72B-Chat",
    "premade_chat_template": true,
    "eos_to_cull": "<|im_end|>",
    "release_date": "30-01-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Swallow-70b-instruct-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "tokyotech-llm/Swallow-70b-instruct-v0.1",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "19-12-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Phi-3-mini-128k-instruct",
    "backend": "huggingface_local",
    "huggingface_id": "microsoft/Phi-3-mini-128k-instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<|endoftext|>",
    "release_date": "22-04-24",
    "open_weight": true,
    "parameters": "3.8B"
  },
  {
    "model_name": "Starling-LM-7B-beta",
    "backend": "huggingface_local",
    "huggingface_id": "Nexusflow/Starling-LM-7B-beta",
    "premade_chat_template": true,
    "eos_to_cull": "<|end_of_turn|>",
    "release_date": "19-03-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Qwen2-7B-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen2-7B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<|im_end|>",
    "release_date": "04-06-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Qwen2-72B-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen2-72B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<|im_end|>",
    "release_date": "28-05-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Llama-3-SauerkrautLM-70b-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<|eot_id|>",
    "release_date": "24-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "aya-23-8B",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "CohereForAI/aya-23-8B",
    "premade_chat_template": true,
    "eos_to_cull": "<|END_OF_TURN_TOKEN|>",
    "release_date": "19-05-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "aya-23-35B",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "CohereForAI/aya-23-35B",
    "premade_chat_template": true,
    "eos_to_cull": "<|END_OF_TURN_TOKEN|>",
    "release_date": "19-05-24",
    "open_weight": true,
    "parameters": "35B"
  },
  {
    "model_name": "gemma-2-9b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-2-9b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<end_of_turn>\n*<eos>",
    "release_date": "24-06-24",
    "open_weight": true,
    "parameters": "9B"
  },
  {
    "model_name": "gemma-2-27b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-2-27b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<end_of_turn>\n*<eos>",
    "release_date": "24-06-24",
    "open_weight": true,
    "parameters": "27B"
  },
  {
    "model_name": "llama-2-7b-chat-hf",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/llama-2-7b-chat-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "18-07-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llama-2-13b-chat-hf",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/llama-2-13b-chat-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "18-07-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "llama-2-70b-chat-hf",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/llama-2-70b-chat-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "18-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "gemma-7b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-7b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "21-02-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "gemma-1.1-2b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-1.1-2b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "26-03-24",
    "open_weight": true,
    "parameters": "2B"
  },
  {
    "model_name": "gemma-1.1-7b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-1.1-7b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "26-03-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "codegemma-7b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/codegemma-7b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "09-04-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "recurrentgemma-2b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/recurrentgemma-2b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "09-04-24",
    "open_weight": true,
    "parameters": "2B"
  },
  {
    "model_name": "gemma-2-2b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-2-2b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "16-07-24",
    "open_weight": true,
    "parameters": "2B"
  },
  {
    "model_name": "Meta-Llama-3.1-8B-Instruct",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<|eot_id|>",
    "release_date": "23-07-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<|eot_id|>",
    "release_date": "23-07-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Mistral-Large-Instruct-2407",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "mistralai/Mistral-Large-Instruct-2407",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "24-07-24",
    "open_weight": true,
    "parameters": "123B"
  },
  {
    "model_name": "Qwen1.5-0.5B-Chat-GGUF-q8",
    "backend": "llamacpp",
    "huggingface_id": "Qwen/Qwen1.5-0.5B-Chat-GGUF",
    "filename": "*q8_0.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<|im_end|>",
    "release_date": "03-02-24",
    "open_weight": true,
    "parameters": "0.5B"
  },
  {
    "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q4",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
    "filename": "*Q4_0.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<|im_end|>",
    "release_date": "31-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
    "filename": "*Q5_0.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<|im_end|>",
    "release_date": "31-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5-k-s",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
    "filename": "*Q5_K_S.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<|im_end|>",
    "release_date": "31-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "EstopianMaid-13B-GGUF-q2-k",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
    "filename": "*Q2_K.gguf",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
    "bos_string": "<s>",
    "eos_string": "</s>",
    "eos_to_cull": "</s>",
    "release_date": "26-01-24",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "EstopianMaid-13B-GGUF-q3-k-s",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
    "filename": "*Q3_K_S.gguf",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
    "bos_string": "<s>",
    "eos_string": "</s>",
    "eos_to_cull": "</s>",
    "release_date": "26-01-24",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "openchat_3.5-GGUF-q5",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/openchat_3.5-GGUF",
    "filename": "*Q5_0.gguf",
    "premade_chat_template": false,
    "custom_chat_template": "{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'].title() + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}",
    "bos_string": "<s>",
    "eos_string": "<|end_of_turn|>",
    "eos_to_cull": "<|end_of_turn|>",
    "release_date": "02-11-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q4",
    "backend": "llamacpp",
    "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
    "filename": "*Q4_K_M.gguf",
    "premade_chat_template": true,
    "bos_string": "<|begin_of_text|>",
    "eos_string": "<|eot_id|>",
    "eos_to_cull": "<|eot_id|>",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q8",
    "backend": "llamacpp",
    "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
    "filename": "*Q8_0-00001-of-00002.gguf",
    "additional_files": ["*Q8_0-00002-of-00002.gguf"],
    "premade_chat_template": true,
    "bos_string": "<|begin_of_text|>",
    "eos_string": "<|eot_id|>",
    "eos_to_cull": "<|eot_id|>",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "c4ai-command-r-plus-GGUF-q4",
    "backend": "llamacpp",
    "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
    "filename": "*Q4_K_M-00001-of-00002.gguf",
    "additional_files": ["*Q4_K_M-00002-of-00002.gguf"],
    "premade_chat_template": true,
    "bos_string": "<BOS_TOKEN>",
    "eos_string": "<|END_OF_TURN_TOKEN|>",
    "eos_to_cull": "<|END_OF_TURN_TOKEN|>",
    "release_date": "04-04-24",
    "open_weight": true,
    "parameters": "104B"
  },
  {
    "model_name": "c4ai-command-r-plus-GGUF-q8",
    "backend": "llamacpp",
    "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
    "filename": "*Q8_0-00001-of-00003.gguf",
    "additional_files": ["*Q8_0-00002-of-00003.gguf", "*Q8_0-00003-of-00003.gguf"],
    "premade_chat_template": true,
    "bos_string": "<BOS_TOKEN>",
    "eos_string": "<|END_OF_TURN_TOKEN|>",
    "eos_to_cull": "<|END_OF_TURN_TOKEN|>",
    "release_date": "04-04-24",
    "open_weight": true,
    "parameters": "104B"
  },
  {
    "model_name": "llava-1.5-7b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-1.5-7b-hf",
    "model_type": "Vision2Seq",
    "output_split_prefix": "ASSISTANT:",
    "custom_chat_template": "{%- for message in messages -%}{% if message['role'] == 'user' %}{% if message['image'] %}\nUSER: <image>\n{{message['content']}}{% else %}\nUSER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}\nASSISTANT:{{message['content']}}{% endif %}{% endfor %}\nASSISTANT:",
    "release_date": "03-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llava-1.5-13b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-1.5-13b-hf",
    "model_type": "Vision2Seq",
    "output_split_prefix": "ASSISTANT:",
    "custom_chat_template": "{%- for message in messages -%}{% if message['role'] == 'user' %}{% if message['image'] %}\nUSER: <image>\n{{message['content']}}{% else %}\nUSER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}\nASSISTANT:{{message['content']}}{% endif %}{% endfor %}\nASSISTANT:",
    "release_date": "03-01-24",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "llava-v1.6-34b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-34b-hf",
    "model_type": "Vision2Seq",
    "output_split_prefix": "assistant",
    "not_fast": true,
    "padding": true,
    "custom_chat_template": "<|im_start|>system\nAnswer the questions.<|im_end|>{%- for message in messages -%}{% if message['role'] == 'user' %}{% if message['image']%}<|im_start|>user\n<image>\n{{message['content']}}<|im_end|>{% else %}<|im_start|>\nuser\n{{message['content']}}<|im_end|>{% endif %}{% elif message['role'] == 'assistant' %}<|im_start|>assistant\n{{message['content']}}<|im_end|>{% endif %}{% endfor %}<|im_start|>assistant\n",
    "release_date": "17-03-24",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "llava-v1.6-mistral-7b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-mistral-7b-hf",
    "model_type": "Vision2Seq",
    "output_split_prefix": "[/INST]",
    "padding": true,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image']%}[INST] <image>\n{{message['content']}} [/INST]{% else %}[INST]\n{{message['content']}} [/INST]{% endif %}{% elif message['role'] == 'assistant' %}{{message['content']}}{% endif %}{% endfor %}",
    "release_date": "20-02-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llava-v1.6-vicuna-13b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-vicuna-13b-hf",
    "model_type": "Vision2Seq",
    "output_split_prefix": "ASSISTANT:",
    "padding": true,
    "custom_chat_template": "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image'] %}USER:<image>\n{{message['content']}}{% else %}USER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}ASSISTANT:{{message['content']}}{% endif %}{% endfor %}ASSISTANT:",
    "release_date": "17-03-24",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "llava-v1.6-vicuna-7b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-vicuna-7b-hf",
    "model_type": "Vision2Seq",
    "output_split_prefix": "ASSISTANT:",
    "padding": true,
    "custom_chat_template": "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image'] %}USER:<image>\n{{message['content']}}{% else %}USER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}ASSISTANT:{{message['content']}}{% endif %}{% endfor %}ASSISTANT:",
    "release_date": "17-03-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "idefics-80b-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/idefics-80b-instruct",
    "model_type": "Idefics",
    "eos_to_cull": "<end_of_utterance>",
    "output_split_prefix": "Assistant:",
    "supports_multiple_images": true,
    "release_date": "24-07-23",
    "open_weight": true,
    "parameters": "80B"
  },
  {
    "model_name": "idefics-9b-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/idefics-9b-instruct",
    "model_type": "Idefics",
    "eos_to_cull": "<end_of_utterance>",
    "output_split_prefix": "Assistant:",
    "supports_multiple_images": true,
    "release_date": "24-07-23",
    "open_weight": true,
    "parameters": "9B"
  }
]