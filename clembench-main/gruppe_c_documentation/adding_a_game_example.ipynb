{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new game to the framework - FirstLast\n",
    "\n",
    "### Disclaimer\n",
    "This notebook closely follows the tutorial steps from [docs/howto_add_games_example.md](https://github.com/clp-research/clembench/blob/main/docs/howto_add_games_example.md)\n",
    " in the [**clp-research/clembench**](https://github.com/clp-research/clembench) repository. <br> \n",
    "While the core content is derived from the original tutorial, some additional detailed descriptions and explanations have been added to serve as a source of knowledge during the development of our project.\n",
    "\n",
    "## Description\n",
    "- The players should engage in a turn-based conversation about a predefined topic. \n",
    "- Player A starts with an utterance whose first and last token must start with a `predefined letter`, say d. \n",
    "- Player B must then reply with an utterance whose first and last token must be the `next one in the alphabet` (here, an e). <br> <br>\n",
    "And so on, for n turns **(where each turn is comprised by an utterance from A and an utterance from B)**.<br> <br>\n",
    "- If an utterance does not conform to these rules (i.e. it is incorrect), the players lose the game. <br>\n",
    "- `move rule:` If an utterance does not start with 'I SAY: ' (i.e., it is invalid), the game is immediately aborted. <br>\n",
    "- If all utterances up to turn n are valid and correct, the game is successful.\n",
    "\n",
    "For instance, if the topic is **birds**, the initial letter is `h` and the number of turns is 2, this would be a successful game:\n",
    "\n",
    "- Hi! I love birds, but it's hard to identify them. I need help. `(h: hi / help)`\n",
    "- I know what you mean. I can try to help, please describe it. `(i: I/ it)`\n",
    "- Just a moment... Ok, it's blue but looks like an Eurasian jay. `(j: just / jay)`\n",
    "- Kick in more details, otherwise I don't know. `(k: kick / know)`\n",
    "\n",
    "Each turn, we need to check two aspects: \n",
    "- **MOVE_RULE**: Does the utterance start with 'I SAY'?\n",
    "- **GAME_RULE**: Do the first/last tokens start with `predefined_letter`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new game:\n",
    "We will need at least the following components:\n",
    "- **Game resources:** all data, prompt templates and text files that are necessary to create instances of a game and to group these instances into experiments.\n",
    "- **Instances:** JSON containing the configuration of each instance, grouped into experiments. \n",
    "    - This must be done by a script named `instancegenerator.py`, with a class that inherits from `GameInstanceGenerator`.\n",
    "- **Game Master:** Controls and enforces MOVE/GAME Rules, inheriting from GameMaster. \n",
    "    - This must be implemented in a file `master.py`.\n",
    "- **Players:** Defines the programatic behaviour and any other attributes of a player, inheriting from `Player`.\n",
    "    - This can be implemented in a file named `players.py`.\n",
    "- **Game Benchmark:** a class that realises the game, inheriting from `GameBenchmark`. \n",
    "    - This can also live in the file `master.py`.\n",
    "\n",
    "To define an **Episode**, we have to instantiate the initial promopts and define 3 more parameters:\n",
    "- Topic\n",
    "- Letter\n",
    "- Number of Turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining prompts with game rules\n",
    "- In the prompt template we can define variables that can be replaced later.\n",
    "- Prompts have to be adjusted for Player A and B, based on their roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('resources') / 'initial_prompts'\n",
    "\n",
    "with open(path / 'initial_prompt_a.template', 'w') as file:\n",
    "    file.write(\n",
    "        \"Let's play a game. You must have a conversation about $topic with your partner. Your first turn must start and end with words that begin with the letter $letter. The reply of your partner must be similar, with the letter that comes after $letter in the alphabet. Then it's your turn again with the next letter, and so on. You'll do it for $nturns turns. Always start your utterance with I SAY: and then give your answer. If you break the rules, you lose.\"\n",
    "    )\n",
    "\n",
    "with open(path / 'initial_prompt_b.template', 'w') as file:\n",
    "    file.write(\n",
    "        \"Let's play a game. You must have a conversation about $topic with your partner. Their first turn must start and end with words that begin with the letter $letter. Your reply must be similar, with the letter that comes after $letter in the alphabet. Then it's their turn again with the next letter, and so on. You'll do it for $nturns turns. Always start your utterance with I SAY: and then give your answer. If you break the rules, you lose.\"\n",
    "    )\n",
    "\n",
    "# Save topics to topics.txt\n",
    "topics = ['dogs', 'cats', 'birds', 'trees']\n",
    "with open(path / 'topics.txt', 'w') as file:\n",
    "    for topic in topics:\n",
    "        file.write(topic + '\\n') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating game instances\n",
    "- instancegenerator.py will create instances.json\n",
    "- Create Class that inherits from GameInstanceGenerator and define `_on_generate`\n",
    "- In main: Instantiate Class and call `.generate()`method\n",
    "\n",
    "- `_on_generate:` Define experiments and instances, based on what dimensions we want to evaluate later.\n",
    "- `Experiment` Set of instances with the same topic\n",
    "    - `Instance:`\n",
    "        - Initial Letter\n",
    "        - Initial Prompt\n",
    "        - Number of turns\n",
    "\n",
    "The instances.json file should contain everything that the game master needs to set up the configuration of a game play!\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"experiments\": [\n",
    "        {\n",
    "            \"name\": \"NAME_1\",\n",
    "            \"game_instances\": [\n",
    "                {\n",
    "                    \"game_id\": 0,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 1,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"NAME_2\",\n",
    "            \"game_instances\": [\n",
    "                {\n",
    "                    \"game_id\": 0,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 1,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the contents of this cell as games/firstlast/instancegenerator.py\n",
    "import random\n",
    "import string\n",
    "\n",
    "from clemgame.clemgame import GameInstanceGenerator\n",
    "\n",
    "# set the name of the game in the script, as you named the directory\n",
    "# this name will be used everywhere, including in the table of results\n",
    "GAME_NAME = 'firstlast'\n",
    "# we will create 10 instances for each experiment; vary this as you wish\n",
    "N_INSTANCES = 10\n",
    "# if the generation involves randomness, remember to set a random seed\n",
    "SEED = 123\n",
    "\n",
    "class FirstLastGameInstanceGenerator(GameInstanceGenerator):\n",
    "    def __init__(self):\n",
    "        # GameInstanceGenerator\n",
    "        super().__init__(GAME_NAME)\n",
    "    \n",
    "    # define on_generate, a mandatory method\n",
    "    def on_generate(self):\n",
    "        # get the list of topics, which will be our experiments\n",
    "        topics = self.load_file('resources/topics.txt').strip('\\n').split('\\n')\n",
    "        # get the prompts for player a and player b\n",
    "        # we'll keep the prompts fixed in all instances, replacing only the\n",
    "        # necessary slots (but you can do it differently)\n",
    "        prompt_a = self.load_template('resources/initial_prompts/initial_prompt_a')\n",
    "        prompt_b = self.load_template('resources/initial_prompts/initial_prompt_b')\n",
    "\n",
    "        # building the file, one experiment at a time\n",
    "        for topic in topics:\n",
    "            # create an experiment (for us, named after a topic)\n",
    "            experiment = self.add_experiment(topic)\n",
    "            # build N_INSTANCES instances for each experiment\n",
    "            for game_id in range(N_INSTANCES):\n",
    "                # set the parameters\n",
    "                # here we do it randomly, but that can also be read from a file\n",
    "                # one of the first 5 letters in the alphabet\n",
    "                letter = random.choice(string.ascii_lowercase[:5])\n",
    "                # up to 8 turns, so that we don't run out of letters\n",
    "                n_turns = random.randint(3, 8)\n",
    "                # create a game instance, using a game_id counter/index\n",
    "                instance = self.add_game_instance(experiment, game_id)\n",
    "                # populate the game instance with its parameters\n",
    "                instance['first_letter'] = letter\n",
    "                instance['n_turns'] = n_turns\n",
    "                instance['prompt_player_a'] = self.create_prompt(\n",
    "                    topic, prompt_a, letter, n_turns)\n",
    "                instance['prompt_player_b'] = self.create_prompt(\n",
    "                    topic, prompt_b, letter, n_turns)\n",
    "    \n",
    "    # an additional method, specific for our example\n",
    "    def create_prompt(self,\n",
    "                      topic: str,\n",
    "                      prompt: str,\n",
    "                      letter: str,\n",
    "                      n_turns: int) -> str:\n",
    "        \"\"\"Replace a prompt template with slot values.\"\"\"\n",
    "        text = string.Template(prompt).substitute(topic=topic, letter=letter,\n",
    "                                                  nturns=n_turns)\n",
    "        return text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    random.seed(SEED)\n",
    "    # always call this, which will actually generate and save the JSON file\n",
    "    FirstLastGameInstanceGenerator().generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"experiments\": [\n",
    "        {\n",
    "            \"name\": \"dogs\",\n",
    "            \"game_instances\": [\n",
    "                {\n",
    "                    \"game_id\": 0,\n",
    "                    \"first_letter\": \"a\",\n",
    "                    \"n_turns\": 5,\n",
    "                    \"prompt_player_a\": \"Test Prompt A\",\n",
    "                    \"prompt_player_b\": \"Test Prompt B\"\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 1,\n",
    "                    \"first_letter\": \"a\",\n",
    "                    \"n_turns\": 6,\n",
    "                    \"prompt_player_a\": \"Test Prompt A\",\n",
    "                    \"prompt_player_b\": \"Test Prompt B\"\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 2,\n",
    "                    \"first_letter\": \"c\",\n",
    "                    \"n_turns\": 3,\n",
    "                    \"prompt_player_a\": \"Test Prompt A\",\n",
    "                    \"prompt_player_b\": \"Test Prompt B\"\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 3,\n",
    "                    \"first_letter\": \"a\",\n",
    "                    \"n_turns\": 6,\n",
    "                    \"prompt_player_a\": \"Test Prompt A\",\n",
    "                    \"prompt_player_b\": \"Test Prompt B\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Game\n",
    "- `master.py`: Implement a Class that inherits from **GameMaster**,\n",
    "    - Define how the game is played\n",
    "    - Enforce Rules\n",
    "    - Log actions for later evaluation\n",
    "\n",
    "### Player Class\n",
    "- Role of Player A and B are symmetric in this case, so we can instantiate both with the same class\n",
    "- `_custom_response()`: Useful in two cases: player is really a program / testing your program -> `model_name = \"programmatic\"`\n",
    "- Includes List to present dialogue history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the contents of this cell as games/firstlast/players.py\n",
    "\n",
    "import random\n",
    "from string import ascii_lowercase as letters\n",
    "from typing import List\n",
    "\n",
    "from clemgame.clemgame import Player\n",
    "\n",
    "\n",
    "class Speaker(Player):\n",
    "    def __init__(self, model_name: str, player: str, letter: str):\n",
    "        # always initialise the Player class with the model_name argument\n",
    "        # if the player is a program and you don't want to make API calls to\n",
    "        # LLMS, use model_name=\"programmatic\"\n",
    "        super().__init__(model_name)\n",
    "        self.player: str = player\n",
    "        self.initial_letter: str = letter\n",
    "\n",
    "        # a list to keep the dialogue history\n",
    "        self.history: List = []\n",
    "\n",
    "    # implement this method as you prefer, with these same arguments\n",
    "    def _custom_response(self, messages, turn_idx) -> str:\n",
    "        \"\"\"Return a mock message with the suitable letter and format.\"\"\"\n",
    "        # get the first letter of the content of the last message\n",
    "        # messages is a list of dictionaries with messages in openai API format\n",
    "        if turn_idx == 1 and self.player == 'A':\n",
    "            letter = 'I SAY: ' + self.initial_letter\n",
    "        else:\n",
    "            previous_letter = messages[-1]['content'][7].lower()\n",
    "            # introduce a small probability that the player fails\n",
    "            letter = self._sample_letter(previous_letter)\n",
    "        # return a string whose first and last tokens start with the next letter     \n",
    "        return f\"{letter}xxx from {self.player}, turn {turn_idx} {letter.replace('I SAY: ', '')}xxx.\"\n",
    "\n",
    "    # an additional method specific for this game\n",
    "    # for testing, we want the utterances to be invalid or incorrect sometimes\n",
    "    def _sample_letter(self, letter: str) -> str:\n",
    "        \"\"\"Randomly decide which letter to use in the message.\"\"\"\n",
    "        prob = random.random() \n",
    "        index = letters.index(letter)\n",
    "        if prob < 0.05:\n",
    "            # correct but invalid (no tag)\n",
    "            return letters[index + 1]\n",
    "        if prob < 0.1:\n",
    "            # valid tag but wrong letter\n",
    "            return 'I SAY: ' + letter\n",
    "        # valid and correct\n",
    "        return 'I SAY: ' + letters[index + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GameMaster Class\n",
    "- Class inherits from **GameMaster**, implement `setup()` and `play()` methods to create and run **episodes** and `compute_scores()`, that will calculate the metrics for the evaluation.\n",
    "- Scores are computed after the game is done using the separate **score** argument of the cli script.  \n",
    "- Metrics that every game must compute are defined in `clemgame/metrics.py`\n",
    "\n",
    "#### Initialisation\n",
    "- First define how to initialise **GameMaster**\n",
    "- `__init__` Method gets the experiment object and a list of Player names as strings.\n",
    "    - Any needed attributes should be initialised here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Dict, Tuple\n",
    "from string import ascii_lowercase as letters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import clemgame.metrics as ms\n",
    "from clemgame.clemgame import GameMaster, GameBenchmark\n",
    "from clemgame import get_logger\n",
    "\n",
    "from games.firstlast.players import Speaker\n",
    "from games.firstlast.instancegenerator import GAME_NAME\n",
    "\n",
    "class FirstLast(GameMaster):\n",
    "    \"\"\"Implement mechanisms for playing FirstLast.\"\"\"\n",
    "    def __init__(self, experiment: Dict, player_backends: List[str]):\n",
    "        super().__init__(GAME_NAME, experiment, player_backends)\n",
    "\n",
    "        # save experiment and player attributes that will be necessary later\n",
    "        self.topic = experiment['name']\n",
    "        self.model_a = player_backends[0]\n",
    "        self.model_b = player_backends[1]\n",
    "\n",
    "        # initialise attributes that will be used for the evaluation scores\n",
    "        self.aborted: bool = False\n",
    "        self.lose: bool = False\n",
    "        self.complete_turns: int = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "The **GameRecorder** class has built-in methods for logging, some of the most important:\n",
    "- At the beginning of every turn, call `log_next_turn()`.\n",
    "- In the Game Setup, call `log_players()` to save the models.\n",
    "- Use `log_event()` to log all types of actions with `from_` and `to`.\n",
    "- The `action` Object passed to `log_event()` must contain a key `type` and a key `content`.\n",
    "    - `type`: Type of message, like send/get msg, error, parse, metadata, etc.\n",
    "    - `content`: The actual content of the message.\n",
    "- Use only values `Player 1`, `Player 2`, `GM`, for the `from_` and `to` arguments.\n",
    "    - `GM` in `from_` and `to`: Anything that GM emits.\n",
    "- All events that involve making an API call should pass an additional `call` argument to `log_event()` containing API input/output.\n",
    "- Besides events, the GM also has to compute and log scores: episode level / turn level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "The setup method gets all `keys=values` in the instance dictionary, as we defined above. <br>\n",
    "- In the Example:\n",
    "    - Instantiate both players and empty dialogue histories\n",
    "    - initial turn index\n",
    "    - initial letter\n",
    "    - some other variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(self, first_letter: str, n_turns: int, prompt_player_a: str,\n",
    "              prompt_player_b: str, game_id: int) -> None:\n",
    "        \"\"\"Setup the episode (mandatory).\"\"\"\n",
    "\n",
    "        self.n_turns = n_turns\n",
    "\n",
    "        # instantiate both players\n",
    "        self.player_a = Speaker(self.model_a, 'A', first_letter)\n",
    "        self.player_b = Speaker(self.model_b, 'B', first_letter)\n",
    "\n",
    "        # initialise game variables\n",
    "        self.current_turn: int = 0\n",
    "        self.current_letter: str = first_letter\n",
    "\n",
    "        # initialise common metrics\n",
    "        self.request_counts = [0] * (n_turns + 1)\n",
    "        self.parsed_request_counts = [0] * (n_turns + 1)\n",
    "        self.violated_request_counts = [0] * (n_turns + 1)\n",
    "\n",
    "        # add initial prompts to each player's messages\n",
    "        self.initiate(prompt_player_a, prompt_player_b)\n",
    "\n",
    "        # always log the details of the players in this format (see logdoc)\n",
    "        self.log_players({\n",
    "            'GM': 'Game master for FirstLast',\n",
    "            'Player 1': f'Player A: {self.model_a}',\n",
    "            'Player 2': f'Player B: {self.model_b}'\n",
    "            })\n",
    "\n",
    "        # log any additional keys that will be relevant for evaluation\n",
    "        self.log_key('n_turns', n_turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary Methods\n",
    "The `play()` Method is broken down into different modules:\n",
    "- proceed()\n",
    "- update_letter()\n",
    "- _append_utterance()\n",
    "- parse()\n",
    "- check_correctness()\n",
    "- log_eval_assets()\n",
    "All of these are defined in `tutorial_first_last/master.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a turn\n",
    "1. Send the initial prompt to player A\n",
    "2. Get player A's response\n",
    "3. Check if response can be parsed -> if not: abort or loop\n",
    "4. Check `GAME_RULE`\n",
    "5. Repeat for Player B\n",
    "6. Log all events in-between all steps\n",
    "\n",
    "- The dialogue history has to be built:\n",
    "    - Messages produced by player: **assistant**\n",
    "    - Messages recieved by player: **user** \n",
    "    - `swap` roles for player B <-> Player A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing scores for the evaluation\n",
    "- During the game play, some attributes kept track of counters that are used for the evaluation, but we have not computed all evaluation scores yet. <br>\n",
    "- This is done by the mandatory `compute_scores()` method. <br>\n",
    "- It gets the full `interaction.json` file as input and must compute and log both turn-level and episode-level scores. <br>\n",
    "- This is a separate step which does not occur in the same runtime as the game play.  <br>\n",
    "- Therefore, all relevant information should get saved into `interaction.json` and accessed again by `compute_scores()` when scoring. <br>\n",
    "- `Important:` If the game is aborted, all episode-level scores must be set to `numpy.nan` and turn-level scores can be computed for the valid turns before the abortion action.\n",
    "- All games must compute `METRIC_ABORTED`, the binary `METRIC_SUCCESS`, and its `BENCH_SCORE` (0=fail, 100=success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GameBenchMark\n",
    "- Final step that \"informs\" the framework about the game\n",
    "- You have to implement a child class of `GameBenchMark`, which defines if the game is single player or not\n",
    "- Implementation can be found in `games/tutorial_first_last/master.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "After adding all these files together, we can run the game by `python3 scripts/cli.py run -g tutorial_first_last -m gpt-4o-2024-08-06`. <br>\n",
    "We get the following results:\n",
    "```\n",
    "2024-09-02 19:43:50,427 - benchmark.run - INFO - Run experiment 1 of 4: dogs\n",
    "Playing games: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.28it/s]\n",
    "2024-09-02 19:43:58,267 - benchmark.run - INFO - Run experiment 2 of 4: cats\n",
    "Playing games: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\n",
    "2024-09-02 19:44:05,414 - benchmark.run - INFO - Run experiment 3 of 4: birds\n",
    "Playing games: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n",
    "2024-09-02 19:44:12,915 - benchmark.run - INFO - Run experiment 4 of 4: trees\n",
    "Playing games: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.24it/s]\n",
    "```\n",
    "\n",
    "Which means that the execution was successful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing Results\n",
    "Now that the interactions and all important metrics have been saved to the `results` folder, we can create a transcription for a better overview of the game.\n",
    "- `python3 scripts/cli.py transcribe -g tutorial_first_last` <br>\n",
    "This results in a readable version of each `episode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores\n",
    "Scoring also goes through with the following results:\n",
    "```\n",
    "2024-09-02 20:13:08,347 - benchmark.run - INFO - Score game 1 of 1: tutorial_first_last\n",
    "2024-09-02 20:13:08,347 - benchmark.run - INFO - Scoring: trees\n",
    "Scoring episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 3409.45it/s]\n",
    "2024-09-02 20:13:08,352 - benchmark.run - ERROR - tutorial_first_last: '10' exceptions occurred: See clembench.log for details.\n",
    "2024-09-02 20:13:08,352 - benchmark.run - INFO - Scoring: birds\n",
    "Scoring episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 4146.21it/s]\n",
    "2024-09-02 20:13:08,355 - benchmark.run - ERROR - tutorial_first_last: '10' exceptions occurred: See clembench.log for details.\n",
    "2024-09-02 20:13:08,355 - benchmark.run - INFO - Scoring: cats\n",
    "Scoring episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 4822.15it/s]\n",
    "2024-09-02 20:13:08,357 - benchmark.run - ERROR - tutorial_first_last: '10' exceptions occurred: See clembench.log for details.\n",
    "2024-09-02 20:13:08,357 - benchmark.run - INFO - Scoring: dogs\n",
    "Scoring episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 4728.64it/s]\n",
    "2024-09-02 20:13:08,360 - benchmark.run - ERROR - tutorial_first_last: '10' exceptions occurred: See clembench.log for details.\n",
    "\n",
    "```\n",
    "\n",
    "We need to look into why the exceptions occurred but overall the game runs, and this can be a good base for implementing our own. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
